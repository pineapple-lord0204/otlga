# OTLGA: Optimal Transport with Local-Global Attention

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.9.0+-orange.svg)](https://pytorch.org/)

**OTLGA** (Optimal Transport with Local-Global Attention) æ˜¯ä¸€ä¸ªç”¨äºåŒ»å­¦å½±åƒå’Œæ”¾å°„å­¦æŠ¥å‘ŠåŒå‘æ£€ç´¢çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚

## ğŸ¯ æ ¸å¿ƒåˆ›æ–°

1. **å±€éƒ¨-å…¨å±€æ³¨æ„åŠ› (LGA)**: å¢å¼ºå±€éƒ¨ç‰¹å¾ä¸å…¨å±€ä¸Šä¸‹æ–‡çš„äº¤äº’
2. **ç†µæ­£åˆ™æœ€ä¼˜ä¼ è¾“ (OT)**: å®ç°ç»†ç²’åº¦çš„å›¾åƒ-æ–‡æœ¬å¯¹é½
3. **OTå¼•å¯¼é—¨æ§èåˆ**: åŠ¨æ€èåˆå¯¹é½åçš„è·¨æ¨¡æ€ç‰¹å¾

## ğŸ“ æ–‡ä»¶ç»“æ„

```
otlga_github/
â”œâ”€â”€ otlga_model.py              # æ ¸å¿ƒæ¨¡å‹å®šä¹‰ (OTLGAModel)
â”œâ”€â”€ otlga_model_ablation.py     # æ¶ˆèå®éªŒæ¨¡å‹ (OTLGAModelAblation)
â”œâ”€â”€ otlga_dataset.py            # æ•°æ®é›†ç±» (OTLGADataset)
â”œâ”€â”€ vit_custom.py               # Vision Transformer å®ç°
â”œâ”€â”€ modules.py                  # è¾…åŠ©æŸå¤±æ¨¡å— (SentenceContrastive, UncertaintyAuxiliary)
â”œâ”€â”€ train_otlga.py              # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ test_otlga.py               # æµ‹è¯•è¯„ä¼°è„šæœ¬
â”œâ”€â”€ train_ablation.py           # æ¶ˆèå®éªŒè®­ç»ƒè„šæœ¬
â”œâ”€â”€ test_ablation.py            # æ¶ˆèå®éªŒæµ‹è¯•è„šæœ¬
â”œâ”€â”€ requirements.txt            # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ README.md                   # æœ¬æ–‡æ¡£
â””â”€â”€ ABLATION_STUDY.md           # æ¶ˆèå®éªŒè¯´æ˜
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### æ•°æ®å‡†å¤‡

ä½¿ç”¨ MIMIC-CXR æ•°æ®é›†ï¼Œéœ€è¦å‡†å¤‡ï¼š

1. **å›¾åƒæ•°æ®**: ç»„ç»‡åœ¨æ•°æ®ç›®å½•ä¸‹çš„å›¾åƒæ–‡ä»¶
2. **CSVæ ‡æ³¨æ–‡ä»¶**: åŒ…å«ä»¥ä¸‹å­—æ®µçš„CSVæ–‡ä»¶
   - `filename`: å›¾åƒæ–‡ä»¶å
   - `split`: æ•°æ®é›†åˆ’åˆ† (train/valid/test)
   - `label`: æ ‡ç­¾ä¿¡æ¯
   - `org_caption`: åŸå§‹æŠ¥å‘Šæ–‡æœ¬

**æ³¨æ„**: éœ€è¦ä¿®æ”¹ä»£ç ä¸­çš„è·¯å¾„é…ç½®ï¼š
- `train_otlga.py`: ä¿®æ”¹ `data_root` å’Œ `csv_path`
- `test_otlga.py`: ä¿®æ”¹ `data_root` å’Œ `csv_path`
- `train_ablation.py`: ä¿®æ”¹ `data_root` å’Œ `csv_path`
- `test_ablation.py`: ä¿®æ”¹ `data_root` å’Œ `csv_path`

### è®­ç»ƒæ¨¡å‹

#### è®­ç»ƒå®Œæ•´ OTLGA æ¨¡å‹

```bash
python train_otlga.py
```

#### è®­ç»ƒæ¶ˆèå®éªŒé…ç½®

```bash
# è®­ç»ƒå•ä¸ªé…ç½®
python train_ablation.py --config baseline
python train_ablation.py --config lga
python train_ablation.py --config ot
python train_ablation.py --config full

# è®­ç»ƒæ‰€æœ‰é…ç½®
python train_ablation.py --config all
```

### æµ‹è¯•æ¨¡å‹

#### æµ‹è¯•å®Œæ•´æ¨¡å‹

```bash
python test_otlga.py
```

#### æµ‹è¯•æ¶ˆèå®éªŒé…ç½®

```bash
# æµ‹è¯•å•ä¸ªé…ç½®
python test_ablation.py --config baseline
python test_ablation.py --config full

# æµ‹è¯•æ‰€æœ‰é…ç½®
python test_ablation.py --config all
```

## ğŸ—ï¸ æ¨¡å‹æ¶æ„

- **è§†è§‰ç¼–ç å™¨**: ViT-Base (768ç»´)
- **æ–‡æœ¬ç¼–ç å™¨**: BERT-Base (768ç»´)
- **å…±åŒåµŒå…¥ç©ºé—´**: 256ç»´
- **æ ¸å¿ƒæ¨¡å—**: 
  - Local-Global Attention (LGA)
  - Entropic Optimal Transport (OT)
  - OT-guided Gated Fusion


## ğŸ”¬ æ¶ˆèå®éªŒ

é¡¹ç›®åŒ…å«å®Œæ•´çš„æ¶ˆèå®éªŒæ¡†æ¶ï¼Œå¯ä»¥è¯„ä¼°å„ä¸ªæ¨¡å—çš„è´¡çŒ®ï¼š

- **baseline**: åŸºçº¿æ¨¡å‹ï¼ˆæŠ•å½±å±‚ + ITCæŸå¤± + å¥å­çº§å¯¹æ¯”æŸå¤±ï¼‰
- **lga**: ä»…LGAæ¨¡å—
- **ot**: ä»…OTæ¨¡å—
- **gated_fusion**: OT + Gated Fusion
- **lga_ot**: LGA + OT
- **lga_gated**: LGA + OT + Gated Fusion
- **ot_gated**: OT + Gated Fusion
- **full**: å®Œæ•´OTLGAæ¨¡å‹

è¯¦ç»†è¯´æ˜è¯·å‚è€ƒ `ABLATION_STUDY.md`ã€‚

## ğŸ’¾ ä¾èµ–

ä¸»è¦ä¾èµ–åŒ…ï¼ˆè¯¦è§ `requirements.txt`ï¼‰ï¼š

- `torch >= 1.9.0`
- `torchvision >= 0.10.0`
- `transformers >= 4.20.0`
- `pandas >= 1.3.0`
- `numpy >= 1.21.0`
- `tqdm >= 4.62.0`
- `Pillow >= 8.3.0`

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### è®­ç»ƒç¤ºä¾‹

```python
from otlga_model import OTLGAModel
from otlga_dataset import OTLGADataset
from torch.utils.data import DataLoader

# åˆå§‹åŒ–æ¨¡å‹
model = OTLGAModel(
    vit_type='vit_base',
    freeze_vit=False,
    freeze_layers=0,
    c_embed_dim=256
)

# åŠ è½½æ•°æ®
dataset = OTLGADataset(
    data_root="path/to/data",
    csv_path="path/to/data.csv",
    split='train',
    img_size=224
)

dataloader = DataLoader(dataset, batch_size=64, shuffle=True)

# è®­ç»ƒå¾ªç¯
for batch in dataloader:
    image, text_input, label = batch
    v_final, t_final, ot_loss, T_fused = model(image, text_input)
    # ... è®¡ç®—æŸå¤±å¹¶åå‘ä¼ æ’­
```

## ğŸ“„ å¼•ç”¨

å¦‚æœä½¿ç”¨æœ¬æ¨¡å‹ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@article{otlga2024,
  title={OTLGA: Optimal Transport with Local-Global Attention for Medical Image-Text Retrieval},
  author={Your Name},
  journal={Your Journal},
  year={2024}
}
```

## ğŸ“œ è®¸å¯è¯

[è¯·æ·»åŠ æ‚¨çš„è®¸å¯è¯ä¿¡æ¯]

## ğŸ‘¥ ä½œè€…

[è¯·æ·»åŠ ä½œè€…ä¿¡æ¯]

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ MIMIC-CXR æ•°æ®é›†æä¾›è€…ä»¥åŠç›¸å…³å¼€æºé¡¹ç›®çš„è´¡çŒ®ã€‚
